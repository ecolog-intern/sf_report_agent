import requests
import time
import csv
import io
import json
from datetime import datetime
import os
import pandas as pd
import winreg


'''
sfã‹ã‚‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®æ•°å€¤ã‚’å¼•ã£å¼µã‚‹
'''
class OptionIndex:
    def __init__(self, config):
        #sfé–¢ä¿‚
        self.sf_username = config.sf_username
        self.sf_password = config.sf_password
        self.client_id = config.client_id
        self.client_secret = config.client_secret
        self.sf_access_token_URL = config.sf_access_token_URL
        self.sf_report_unique = config.sf_report_unique
        self.api_version = config.api_version
        
        #proxyé–¢ä¿‚
        self.proxies = config.proxies
        self.MAX_RETRIES = config.MAX_RETRIES
        
        #soqlå–å¾—
        self.soql = config.soql

        # ãƒ¬ãƒãƒ¼ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        self.report_meta = config.report_meta

        # output ã® csv ã®ãƒ‘ã‚¹
        now = datetime.now()
        year = now.strftime("%Yå¹´")          # ä¾‹: 2025
        month = now.strftime("%mæœˆ")         # ä¾‹: 01
        file_name = now.strftime("%mæœˆ%dæ—¥.csv")  # ä¾‹: 01æœˆ12æ—¥.csv

        base_dir = config.sf_folder_base_path
        year_dir = os.path.join(base_dir, year)
        month_dir = os.path.join(year_dir, month)

        # ãƒ•ã‚©ãƒ«ãƒ€ã‚’è‡ªå‹•ä½œæˆ
        os.makedirs(month_dir, exist_ok=True)

        # å®Œå…¨ãƒ‘ã‚¹
        self.output_csv_path = os.path.join(month_dir, file_name)
        
    def make_option_matrix(self, df_raw):
        """
        SF ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ â†’ ä»£ç†åº— Ã— OP ã®é›†è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«ã¸å¤‰æ›ã™ã‚‹ã€‚
        æˆ»ã‚Šå€¤ï¼š
            index : ä»£ç†åº—å
            columns : å„OPæ•° + ALLä»˜å¸¯æ•° + ALLä»˜å¸¯ç‡ + å„OPç‡
        """

        df = df_raw.copy()

        # åˆ—æŠ½å‡º
        df = df[[
            "contractor_information__r.Payment_agency_name__c",
            "option_plan_code__r.Name"
        ]].rename(columns={
            "contractor_information__r.Payment_agency_name__c": "ä»£ç†åº—å",
            "option_plan_code__r.Name": "ã‚ªãƒ—ã‚·ãƒ§ãƒ³å"
        })

        # ä»£ç†åº— Ã— OP ã®ä»¶æ•°é›†è¨ˆ
        pivot_df = (
            df.groupby(["ä»£ç†åº—å", "ã‚ªãƒ—ã‚·ãƒ§ãƒ³å"])
            .size()
            .unstack(fill_value=0)
        )

        # ALLä»˜å¸¯æ•°
        pivot_df = pivot_df.reindex(self.agency_names, fill_value=0)
        pivot_df["ALLä»˜å¸¯æ•°"] = pivot_df.sum(axis=1)

        # ALLä»˜å¸¯ç‡ï¼ˆ1.0ã«ãªã‚‹ã‹ç¢ºèªï¼‰
        pivot_df["ALLä»˜å¸¯ç‡"] = (
            pivot_df["ALLä»˜å¸¯æ•°"] / pivot_df["ALLä»˜å¸¯æ•°"]
        ).replace([float('inf'), float('nan')], 0)

        # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼š1.0 ä»¥å¤–ãªã‚‰è­¦å‘Š
        abnormal_rows = pivot_df[pivot_df["ALLä»˜å¸¯ç‡"] != 1.0]
        if not abnormal_rows.empty:
            print(f"âš ã€è­¦å‘Šã€‘ALLä»˜å¸¯ç‡ â‰  100% ã®ä»£ç†åº—ãŒ{len(abnormal_rows)}ä»¶åˆ†ã‚ã‚Šã¾ã™")

        # OPã®å‰²åˆã‚’è¨ˆç®—
        for col in pivot_df.columns:
            if col in ["ALLä»˜å¸¯æ•°", "ALLä»˜å¸¯ç‡"]:
                continue
            pivot_df[f"{col}_ç‡"] = (
                pivot_df[col] / pivot_df["ALLä»˜å¸¯æ•°"]
            ).replace([float('inf'), float('nan')], 0)

        count_cols = [col for col in pivot_df.columns if not col.endswith("ç‡")]
        rate_cols = [col for col in pivot_df.columns if col.endswith("ç‡")]
        pivot_df = pivot_df[count_cols + rate_cols]

        return pivot_df

    def option_extract(self):
        '''
        å®Ÿéš›ã®æŠ½å‡ºå‡¦ç†
        sfã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã¦ã€sfã®ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—
        ãã®ã‚ã¨ã€dataframeã‚’åŠ å·¥
        è¿”ã‚Šå€¤ã¯pandasã®dataframeã§ç¸¦è»¸ãŒä»£ç†åº—åã€æ¨ªè»¸ãŒALLä»˜å¸¯æ•°ã€å„ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ•°ã€ALLä»˜å¸¯ç‡ã€å„ã‚ªãƒ—ã‚·ãƒ§ãƒ³å‰²åˆ
        '''
        for attempt in range(1, self.MAX_RETRIES+1):
            try:
                # proxyã‚¨ãƒ©ãƒ¼å¯¾ç­–
                key_path = r"Software\Microsoft\Windows\CurrentVersion\Internet Settings"
                with winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path, 0, winreg.KEY_SET_VALUE) as key:
                    for i in range(2):
                        # OFF
                        winreg.SetValueEx(key, "ProxyEnable", 0, winreg.REG_DWORD, 0)
                        time.sleep(2)
                        # ON
                        winreg.SetValueEx(key, "ProxyEnable", 0, winreg.REG_DWORD, 1)
                        time.sleep(2)
                
                # èªè¨¼
                access_token, instance_url = self.authenticate_salesforce()
                print(f"[INFO] Connected to {instance_url}")

                # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
                self.run_bulk_query(instance_url, access_token)
                self.df = pd.read_csv(self.output_csv_path)
                print(self.df)
                
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆ{attempt}å›ç›®ï¼‰: {e}")

                if attempt < self.MAX_RETRIES:
                    print("ğŸ” å†å®Ÿè¡Œã—ã¾ã™...\n")
                else:
                    print("ğŸš¨ æœ€å¤§è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    raise   # ã“ã“ã§ã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ã¦çµ‚äº†
                
            else:
                # try ãŒä¸€åº¦ã‚‚ä¾‹å¤–ã‚’å‡ºã•ãšã«å®Œèµ°ã—ãŸã‚‰ã“ã“ã«æ¥ã‚‹
                print("âœ… å‡¦ç†æˆåŠŸï¼")
                return self.make_option_matrix(self.df)

    def authenticate_salesforce(self):
        """
        Salesforce OAuth2èªè¨¼ã‚’è¡Œã†

        Returns:
            (access_token, instance_url)
        """
        payload = {
            "grant_type": "password",
            "client_id": self.client_id,
            "client_secret": self.client_secret,
            "username": self.sf_username,
            "password": self.sf_password
        }

        response = requests.post(self.sf_access_token_URL, data=payload, proxies=self.proxies)
        if response.status_code != 200:
            print("[ERROR] Salesforce authentication failed:")
            print(response.text)
            raise Exception(f"Salesforce authentication failed ({response.status_code})")

        data = response.json()
        return data["access_token"], data["instance_url"]


    def run_bulk_query(self, instance_url, access_token) -> list:
        """
        Bulk API 2.0ã§SOQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã€çµæœã‚’ãƒªã‚¹ãƒˆã§è¿”ã™

        Args:
            instance_url: Salesforceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹URL
            access_token: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³
            soql: SOQLã‚¯ã‚¨ãƒªï¼ˆçœç•¥æ™‚ã¯åŸ‹ã‚è¾¼ã¿ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ï¼‰
            api_version: APIãƒãƒ¼ã‚¸ãƒ§ãƒ³
            output_csv_path: CSVå‡ºåŠ›ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã§ä¿å­˜ï¼‰

        Returns:
            CSVãƒ‡ãƒ¼ã‚¿ã‚’2æ¬¡å…ƒãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™
        """
        
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }

        base_url = f"{instance_url}/services/data/v{self.api_version}/jobs/query"

        # 1. ã‚¸ãƒ§ãƒ–ä½œæˆ
        payload = {
            "operation": "query",
            "query": self.soql,
            "contentType": "CSV"
        }

        job_res = requests.post(base_url, headers=headers, json=payload)

        if not job_res.ok:
            print("[ERROR] Job creation failed")
            print("Status:", job_res.status_code)
            try:
                error_text = json.dumps(job_res.json(), indent=2, ensure_ascii=False)
                print(error_text)
            except Exception:
                print(job_res.text)
            job_res.raise_for_status()

        job_id = job_res.json()["id"]
        print(f"[INFO] Job created: {job_id}")

        # 2. ã‚¸ãƒ§ãƒ–å®Œäº†å¾…ã¡
        while True:
            status_res = requests.get(f"{base_url}/{job_id}", headers=headers)
            status_res.raise_for_status()
            state = status_res.json()["state"]
            print(f"[INFO] Job state: {state}")
            if state in ("JobComplete", "Failed", "Aborted"):
                break
            time.sleep(5)

        if state != "JobComplete":
            print(f"[ERROR] Job ended with state: {state}")
            print(status_res.text)
            raise Exception("Bulk query job failed.")

        # 3. çµæœCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        result_res = requests.get(f"{base_url}/{job_id}/results", headers=headers)
        result_res.raise_for_status()
        decoded = result_res.content.decode("utf-8")
        all_rows = list(csv.reader(io.StringIO(decoded)))

        print(f"[INFO] Retrieved {len(all_rows)} rows (including header)")

        # 4. CSVä¿å­˜ï¼ˆãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        self.save_to_csv(all_rows, self.output_csv_path)

    def save_to_csv(self, data, output_path):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹
        REPORT_METAãŒå®šç¾©ã•ã‚Œã¦ã„ã‚Œã°ã€ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›ã™ã‚‹

        Args:
            data: 2æ¬¡å…ƒãƒªã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # report_metaã‚’ä½¿ç”¨ã—ã¦ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›
        if len(data) > 0 and self.report_meta is not None:
            try:
                detail_columns = self.report_meta.get("detailColumns", [])
                detail_column_info = self.report_meta.get("detailColumnInfo", {})
                data[0] = self._convert_headers_by_soql_mapping(data[0], detail_columns, detail_column_info)
                print(f"[INFO] ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›ã—ã¾ã—ãŸ")
            except Exception as e:
                print(f"[WARN] ã‚«ãƒ©ãƒ åå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        with open(output_path, "w", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            writer.writerows(data)
        print(f"[INFO] Saved to {output_path}")

    def _convert_headers_by_soql_mapping(self, headers_row: list, detail_columns: list, detail_column_info: dict) -> list:
        """
        CSVãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’SOQLãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨detailColumnsã®ãƒãƒƒãƒ”ãƒ³ã‚°ã«åŸºã¥ã„ã¦æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã«å¤‰æ›ã™ã‚‹
        Bulk APIã¯SELECTå¥ã®é †åºã‚’ä¿æŒã—ãªã„ãŸã‚ã€SOQLãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‹ã‚‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ§‹ç¯‰ã™ã‚‹

        Args:
            headers_row: CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆAPIåã®ãƒªã‚¹ãƒˆï¼‰
            detail_columns: ãƒ¬ãƒãƒ¼ãƒˆãƒ¡ã‚¿ã®detailColumnsï¼ˆé †åºä»˜ããƒªã‚¹ãƒˆï¼‰
            detail_column_info: ãƒ¬ãƒãƒ¼ãƒˆãƒ¡ã‚¿ã®detailColumnInfo

        Returns:
            æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã«å¤‰æ›ã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        """
        # SOQLã‹ã‚‰SELECTå¥ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º
        import re
        select_match = re.search(r'SELECT\s+([\s\S]+?)\s+FROM', self.soql, re.IGNORECASE)
        soql_fields = []
        if select_match:
            fields_str = select_match.group(1)
            soql_fields = [f.strip() for f in fields_str.split(',')]

        # SOQLãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆå°æ–‡å­—ï¼‰â†’ detailColumnsã®ãƒ©ãƒ™ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ§‹ç¯‰
        soql_to_label = {}
        if len(soql_fields) == len(detail_columns):
            for soql_field, detail_col in zip(soql_fields, detail_columns):
                if detail_col in detail_column_info:
                    label = detail_column_info[detail_col].get("label", detail_col)
                    soql_to_label[soql_field.lower()] = label

        result = []
        for h in headers_row:
            h_lower = h.lower()
            if h_lower in soql_to_label:
                result.append(soql_to_label[h_lower])
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ãƒ˜ãƒƒãƒ€ãƒ¼åã‚’ä½¿ç”¨
                result.append(h)

        return result


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # è¨­å®šã‚¯ãƒ©ã‚¹ï¼ˆConfigï¼‰ã‚’ä½œæˆã™ã‚‹
    class Config:
        def __init__(self):
            # Salesforceæ¥ç¶šæƒ…å ±
            self.sf_username = "your_username@example.com"
            self.sf_password = "your_password"
            self.client_id = "your_client_id"
            self.client_secret = "your_client_secret"
            self.sf_access_token_URL = "https://login.salesforce.com/services/oauth2/token"
            self.sf_report_unique = "report_id"
            self.api_version = "62.0"

            # ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
            self.proxy_host = "proxy"
            self.proxy_port = "8080"
            self.proxy_user = "pc_username"
            self.proxy_password = "pc_passward"
            self.proxy_user = urllib.parse.quote(self.proxy_user)
            self.proxy_password = urllib.parse.quote(self.proxy_password)

            self.proxies = {
                "http": f"http://{self.proxy_user}:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}",
                "https": f"http://{self.proxy_user}:{self.proxy_password}@{self.proxy_host}:{self.proxy_port}"
            }
            self.MAX_RETRIES = 3

            # SOQLï¼ˆã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯SOQL_QUERYã‚’ä½¿ç”¨ï¼‰
            self.soql = SOQL_QUERY

            # ãƒ¬ãƒãƒ¼ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯REPORT_METAã‚’ä½¿ç”¨ï¼‰
            self.report_meta = REPORT_META

            # CSVå‡ºåŠ›å…ˆã®ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
            self.sf_folder_base_path = "./output"

    # Configã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    config = Config()

    # OptionIndexã‚’å®Ÿè¡Œ
    option_index = OptionIndex(config)

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’å–å¾—
    result_df = option_index.option_extract()
    print(result_df)
